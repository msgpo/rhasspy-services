{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rhasspy Command-Line Tools\n",
    "\n",
    "Rhasspy's various services can be controlled via command-line tools. Many of these tools are intended to be used in Unix pipelines, and are therefore very particular about what they read/write to and from `stdin`/`stdout`.\n",
    "\n",
    "The available tools can be grouped by their function:\n",
    "\n",
    "* Wake word\n",
    "    * Detect wake word in an audio stream\n",
    "* Voice command\n",
    "    * Detect start and stop of voice commands in an audio stream\n",
    "* Training\n",
    "    * Generate speech/intent recognition artifacts\n",
    "* Speech to text\n",
    "    * Transcribe an audio segment\n",
    "* Intent recognition\n",
    "    * Convert text to structured JSON event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GStreamer\n",
    "\n",
    "GStreamer provides tools and plugins for constructing audio/video transformation pipelines.\n",
    "\n",
    "Rhasspy's audio tools (wake word, voice command, etc.) expect a precise audio format (16-bit 16Khz mono PCM), which GStreamer can convert to from a variety of sources. Audio can even be streamed over a network, allowing Rhasspy to receive microphone input remotely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/gst-launch-1.0\r\n"
     ]
    }
   ],
   "source": [
    "# Make sure you have gstreamer installed.\n",
    "# If not, run:\n",
    "# sudo apt-get install gstreamer1.0-pulseaudio gstreamer1.0-tools gstreamer1.0-plugins-good\n",
    "\n",
    "!which gst-launch-1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kate:  katedec: Kate stream text decoder\r\n",
      "kate:  kateenc: Kate stream encoder\r\n",
      "kate:  kateparse: Kate stream parser\r\n",
      "kate:  katetag: Kate stream tagger\r\n",
      "x265:  x265enc: x265enc\r\n",
      "resindvd:  rsndvdbin: rsndvdbin\r\n",
      "uvch264:  uvch264mjpgdemux: UVC H264 MJPG Demuxer\r\n",
      "uvch264:  uvch264src: UVC H264 Source\r\n",
      "libvisual:  libvisual_jess: libvisual jess plugin plugin v.0.1\r\n",
      "libvisual:  libvisual_bumpscope: libvisual Bumpscope plugin plugin v.0.0.1\r\n"
     ]
    }
   ],
   "source": [
    "# Get a list of installed plugins\n",
    "\n",
    "! gst-inspect-1.0 | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory Details:\r\n",
      "  Rank                     primary (256)\r\n",
      "  Long-name                File Source\r\n",
      "  Klass                    Source/File\r\n",
      "  Description              Read from arbitrary point in a file\r\n",
      "  Author                   Erik Walthinsen <omega@cse.ogi.edu>\r\n",
      "\r\n",
      "Plugin Details:\r\n",
      "  Name                     coreelements\r\n",
      "  Description              GStreamer core elements\r\n"
     ]
    }
   ],
   "source": [
    "# See details for a specific plugin\n",
    "\n",
    "! gst-inspect-1.0 filesrc | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting pipeline to PAUSED ...\n",
      "Pipeline is PREROLLING ...\n",
      "Redistribute latency...\n",
      "Pipeline is PREROLLED ...\n",
      "Setting pipeline to PLAYING ...\n",
      "New clock: GstPulseSinkClock\n",
      "Got EOS from element \"pipeline0\".\n",
      "Execution ended after 0:00:02.404596137\n",
      "Setting pipeline to PAUSED ...\n",
      "Setting pipeline to READY ...\n",
      "Setting pipeline to NULL ...\n",
      "Freeing pipeline ...\n"
     ]
    }
   ],
   "source": [
    "# Play an audio file using a pipeline.\n",
    "# You can also just use gst-play-1.0 <FILE>\n",
    "\n",
    "! gst-launch-1.0 \\\n",
    "    filesrc location=wav/turn_on_living_room_lamp.wav ! \\\n",
    "    decodebin ! \\\n",
    "    autoaudiosink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wake Word (Porcupine)\n",
    "\n",
    "Rhasspy uses [porcupine](https://github.com/Picovoice/Porcupine) to detect wake words. By default, the `rhasspy-porcupine` command expects an audio stream on `stdin` and listens for the word \"porcupine\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'k' to see a list of keyboard shortcuts.\n",
      "Now playing /home/hansenm/opt/rhasspy-services/docs/notebooks/wav/porcupine.wav\n",
      "Redistribute latency...\n",
      "0:00:01.2 / 0:00:01.2       \n",
      "Reached end of play list.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Play wake word sample\n",
    "! gst-play-1.0 wav/porcupine.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\r\n",
      "  \u001b[0m\u001b[34;1m\"index\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"keyword\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"/home/hansenm/opt/rhasspy-services/wake_word/porcupine/resources/keyword_files/linux/porcupine_linux.ppn\"\u001b[0m\u001b[1;39m\r\n",
      "\u001b[1;39m}\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Detect wake word.\n",
    "# Requires 16-bit 16Khz mono audio.\n",
    "! gst-launch-1.0 \\\n",
    "    filesrc location=wav/porcupine.wav ! \\\n",
    "    decodebin ! \\\n",
    "    audioconvert ! \\\n",
    "    audioresample ! \\\n",
    "    audio/x-raw, rate=16000, channels=1, format=S16LE ! \\\n",
    "    filesink location=/dev/stdout | \\\n",
    "  rhasspy-porcupine | \\\n",
    "  jq ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voice Commands (webrtcvad)\n",
    "\n",
    "Rhasspy uses [webrtcvad](https://github.com/wiseman/py-webrtcvad) to detect speech. Combined with some heuristics, `rhasspy-webrtcvad` will detect when a voice command starts and stops. This command expects an audio stream on `stdin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rhasspy/voice-command/speech {\"seconds\": 0.06}\r\n",
      "rhasspy/voice-command/command-started {\"seconds\": 0.6000000000000001}\r\n",
      "rhasspy/voice-command/silence {\"seconds\": 3.3000000000000025}\r\n",
      "rhasspy/voice-command/command-stopped {\"seconds\": 3.900000000000003}\r\n"
     ]
    }
   ],
   "source": [
    "# Requires 16-bit 16Khz mono audio\n",
    "! gst-launch-1.0 \\\n",
    "    filesrc location=wav/turn_on_living_room_lamp.wav ! \\\n",
    "    decodebin ! \\\n",
    "    audioconvert ! \\\n",
    "    audioresample ! \\\n",
    "    audio/x-raw, rate=16000, channels=1, format=S16LE ! \\\n",
    "    filesink location=/dev/stdout | \\\n",
    "  rhasspy-webrtcvad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Rhasspy's voice commands are pre-specified in a file named `sentences.ini`, which contains simplifed [JSGF grammars](https://www.w3.org/TR/jsgf/) grouped by intent. The training process involes:\n",
    "\n",
    "1. Extracting the JSGF grammars\n",
    "2. Converting them to finite state transducers (FSTs)\n",
    "3. Merging the FSTs into `intent.fst`\n",
    "4. Converting `intent.fst` to an [ARPA language model](https://cmusphinx.github.io/wiki/arpaformat/)\n",
    "\n",
    "Assuming `profile` directory contains:\n",
    "\n",
    "* `sentences.ini`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Loaded ini file\r\n",
      "DEBUG:root:Wrote profile/grammars/GetTime.gram (1 rule(s))\r\n",
      "DEBUG:root:Wrote profile/grammars/GetTemperature.gram (1 rule(s))\r\n",
      "DEBUG:root:Wrote profile/grammars/GetGarageState.gram (1 rule(s))\r\n",
      "DEBUG:root:Wrote profile/grammars/ChangeLightState.gram (3 rule(s))\r\n",
      "DEBUG:root:Wrote profile/grammars/ChangeLightColor.gram (3 rule(s))\r\n"
     ]
    }
   ],
   "source": [
    "# Generate grammars from sentences.ini\n",
    "! rhasspy-ini_jsgf \\\n",
    "    --ini-file profile/sentences.ini \\\n",
    "    --grammar-dir profile/grammars \\\n",
    "    --debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChangeLightColor.gram  GetGarageState.gram  GetTime.gram\r\n",
      "ChangeLightState.gram  GetTemperature.gram\r\n"
     ]
    }
   ],
   "source": [
    "# Show generated grammars\n",
    "! ls profile/grammars/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Parsing JSGF grammar GetTime.gram\n",
      "DEBUG:root:Parsing JSGF grammar ChangeLightState.gram\n",
      "DEBUG:root:Parsing JSGF grammar GetTemperature.gram\n",
      "DEBUG:root:Parsing JSGF grammar ChangeLightColor.gram\n",
      "DEBUG:root:Parsing JSGF grammar GetGarageState.gram\n",
      "DEBUG:root:Processing GetTime\n",
      "DEBUG:root:Processing ChangeLightState\n",
      "DEBUG:root:Processing GetTemperature\n",
      "DEBUG:root:Processing ChangeLightColor\n",
      "DEBUG:root:Processing GetGarageState\n",
      "DEBUG:root:Wrote intent FST to profile/intent.fst\n",
      "DEBUG:root:Generated FSTs in 0.07654190063476562 second(s)\n",
      "DEBUG:root:['ngramcount', 'profile/intent.fst', '/tmp/tmpj_j5fyei']\n",
      "DEBUG:root:['ngrammake', '/tmp/tmpj_j5fyei', '/tmp/tmp87fbnrta']\n",
      "DEBUG:root:['ngramprint', '--ARPA', '/tmp/tmp87fbnrta']\n",
      "DEBUG:root:Wrote ARPA language model to profile/language_model.txt\n",
      "DEBUG:root:Wrote vocabulary to profile/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "# Convert grammars to FSTs and a language model\n",
    "! rhasspy-jsgf_fst_arpa \\\n",
    "    --grammar-dir profile/grammars \\\n",
    "    --fst-dir profile/fsts \\\n",
    "    --fst profile/intent.fst \\\n",
    "    --vocab profile/vocab.txt \\\n",
    "    --arpa profile/language_model.txt \\\n",
    "    --debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChangeLightColor.fst  GetGarageState.fst  GetTime.fst\r\n",
      "ChangeLightState.fst  GetTemperature.fst\r\n"
     ]
    }
   ],
   "source": [
    "# Show generated FSTs\n",
    "! ls profile/fsts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tell\r\n",
      "what\r\n",
      "me\r\n",
      "the\r\n",
      "time\r\n",
      "is\r\n",
      "it\r\n",
      "turn\r\n",
      "bedroom\r\n",
      "light\r\n"
     ]
    }
   ],
   "source": [
    "# Custom vocabulary\n",
    "! head profile/vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\\data\\\r\n",
      "ngram 1=32\r\n",
      "ngram 2=72\r\n",
      "ngram 3=94\r\n",
      "\r\n",
      "\\1-grams:\r\n",
      "-99\t<s>\t-2.911084\r\n",
      "-0.7585103\t</s>\r\n",
      "-2.448706\ttell\t-2.998452\r\n"
     ]
    }
   ],
   "source": [
    "# Custom ARPA language model\n",
    "! head profile/language_model.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Training (Pocketsphinx)\n",
    "\n",
    "The CMU English model for [Pocketsphinx](https://github.com/cmusphinx/pocketsphinx) uses [ARPABET](https://en.wikipedia.org/wiki/Arpabet) phonemes to describe word pronunciations. A large pronunciation dictionary has been provided, and was used to generate a grapheme-to-phoneme model with [Phonetisaurus](https://github.com/AdolfVonKleist/Phonetisaurus).\n",
    "\n",
    "Assuming `profile` directory contains:\n",
    "\n",
    "* `base_dictionary.txt` (pronunciation dictionary)\n",
    "* `g2p.fst` (grapheme-to-phoneme model)\n",
    "\n",
    "[Download Link](https://github.com/synesthesiam/rhasspy-profiles/releases/download/v1.0-en/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Loading dictionary from profile/base_dictionary.txt\n",
      "DEBUG:root:Loaded 30 word(s) from profile/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "# Generate custom dictionary for vocabulary\n",
    "! rhasspy-vocab_dict \\\n",
    "    --vocab profile/vocab.txt \\\n",
    "    --dictionary profile/base_dictionary.txt \\\n",
    "    --debug > profile/dictionary.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedroom B EH D R UW M\r\n",
      "blue B L UW\r\n",
      "closed K L OW Z D\r\n",
      "cold K OW L D\r\n",
      "door D AO R\r\n",
      "garage G ER AA ZH\r\n",
      "green G R IY N\r\n",
      "hot HH AA T\r\n",
      "how HH AW\r\n",
      "is IH Z\r\n"
     ]
    }
   ],
   "source": [
    "# Custom dictionary\n",
    "! head profile/dictionary.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guess unknown word pronunciations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing profile/unknown_words.txt\n"
     ]
    }
   ],
   "source": [
    "%%file profile/unknown_words.txt\n",
    "test\n",
    "ploop\n",
    "raxacoricofallipatorius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\r\n",
      "  \u001b[0m\u001b[34;1m\"test\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\r\n",
      "    \u001b[0;32m\"T EH S T\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"T AH S T\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"T IH S T\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"T S T\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"T IY S T\"\u001b[0m\u001b[1;39m\r\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"ploop\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\r\n",
      "    \u001b[0;32m\"P L UW P\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"P L OW AO P\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"P L OW AA P\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"P L AA AO P\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"P L UW P IY\"\u001b[0m\u001b[1;39m\r\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"raxacoricofallipatorius\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\r\n",
      "    \u001b[0;32m\"R AE K S AH K AO R IH K AO F AE L AH P AH T AO R IY IH S\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"R AE K S AH K AO R IY K OW F AE L AH P AH T AO R IY IH S\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"R AE K S AH K AO R AH K OW F AE L AH P AH T AO R IY IH S\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"R AE K S AH K AA R IH K AO F AE L AH P AH T AO R IY IH S\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"R AE K S AH K AO R IH K OW F AE L AH P AH T AO R IY IH S\"\u001b[0m\u001b[1;39m\r\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m\r\n",
      "\u001b[1;39m}\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Guesses can be added to dictionary as:\n",
    "# <WORD> <PHONEMES>\n",
    "! rhasspy-vocab_g2p \\\n",
    "    --model profile/g2p.fst \\\n",
    "    < profile/unknown_words.txt | \\\n",
    "  jq ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to Text (Pocketsphinx)\n",
    "\n",
    "Transcription of an audio segment with [Pocketsphinx](https://github.com/cmusphinx/pocketsphinx) requires three artifacts:\n",
    "\n",
    "1. An acoustic model\n",
    "    * Provided by CMU for English\n",
    "2. A pronunciation dictionary\n",
    "    * Generated by extracting custom vocabulary from base dictionary\n",
    "3. An ARPA language model\n",
    "    * Generated using [Opengrm](http://www.opengrm.org/twiki/bin/view/GRM/NGramLibrary)\n",
    "\n",
    "Assumes `profile` contains:\n",
    "\n",
    "* `acoustic_model` (cmusphinx-en-us-5.2 16Khz)\n",
    "* `dictionary.txt` (from training)\n",
    "* `language_model.txt` (from training)\n",
    "\n",
    "[Download Link](https://github.com/synesthesiam/rhasspy-profiles/releases/download/v1.0-en/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\r\n",
      "  \u001b[0m\u001b[34;1m\"text\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"turn on the living room lamp\"\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"transcribe_seconds\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0.11563658714294434\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"likelihood\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0.5971662313418215\u001b[0m\u001b[1;39m\r\n",
      "\u001b[1;39m}\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Requires 16-bit 16Khz mono audio\n",
    "! gst-launch-1.0 \\\n",
    "    filesrc location=wav/turn_on_living_room_lamp.wav ! \\\n",
    "    decodebin ! \\\n",
    "    audioconvert ! \\\n",
    "    audioresample ! \\\n",
    "    audio/x-raw, rate=16000, channels=1, format=S16LE ! \\\n",
    "    filesink location=/dev/stdout | \\\n",
    "  rhasspy-pocketsphinx \\\n",
    "    --acoustic-model profile/acoustic_model \\\n",
    "    --dictionary profile/dictionary.txt \\\n",
    "    --language-model profile/language_model.txt | \\\n",
    "  jq ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decode multiple WAV files ([jsonl](http://jsonlines.org/) output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wav_files.txt\n"
     ]
    }
   ],
   "source": [
    "%%file wav_files.txt\n",
    "wav/turn_on_living_room_lamp.wav\n",
    "wav/what_time_is_it.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\r\n",
      "  \u001b[0m\u001b[34;1m\"text\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"turn on the living room lamp\"\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"transcribe_seconds\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0.11560416221618652\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"likelihood\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0.5345806918647441\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"wav_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"turn_on_living_room_lamp.wav\"\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"wav_seconds\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m2.402375\u001b[0m\u001b[1;39m\r\n",
      "\u001b[1;39m}\u001b[0m\r\n",
      "\u001b[1;39m{\r\n",
      "  \u001b[0m\u001b[34;1m\"text\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"what time is it\"\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"transcribe_seconds\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0.17764925956726074\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"likelihood\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0.019605291722447564\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"wav_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"what_time_is_it.wav\"\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"wav_seconds\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m2.218667\u001b[0m\u001b[1;39m\r\n",
      "\u001b[1;39m}\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Reads list of WAV files to decode from stdin\n",
    "! rhasspy-pocketsphinx_wavs2text \\\n",
    "    --acoustic-model profile/acoustic_model \\\n",
    "    --dictionary profile/dictionary.txt \\\n",
    "    --language-model profile/language_model.txt \\\n",
    "    < wav_files.txt | \\\n",
    "  jq ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Training (Kaldi)\n",
    "\n",
    "Rhasspy supports the [Kaldi](https://kaldi-asr.org) speech recognition toolkit for audio segment transcription. Both `nnet3` and `gmm` model types can be trained and used for decoding.\n",
    "\n",
    "The [zamia](https://github.com/gooofy/zamia-speech) TDNN English model has been tested, and uses the [International Phonetic Alphabet](https://en.wikipedia.org/wiki/International_Phonetic_Alphabet) for its pronunciation dictionary.\n",
    "\n",
    "Assumes `profile/kaldi` contains:\n",
    "\n",
    "* `model` (nnet3)\n",
    "    * `conf`\n",
    "        * `mfcc_hires.conf`\n",
    "    * `phones`\n",
    "        * `phones.txt`\n",
    "        * `nonsilence_phones.txt`\n",
    "        * `silence_phones.txt`\n",
    "        * `optional_silence.txt`\n",
    "        * `extra_questions.txt`\n",
    "    * `model`\n",
    "        * `final.mdl`\n",
    "        *  `tree`\n",
    "* `base_dictionary.txt`\n",
    "* `g2p.fst`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Loading dictionary from profile/kaldi/base_dictionary.txt\n",
      "DEBUG:root:Loaded 30 word(s) from profile/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "# Generate custom dictionary for vocabulary\n",
    "! rhasspy-vocab_dict \\\n",
    "    --vocab profile/vocab.txt \\\n",
    "    --dictionary profile/kaldi/base_dictionary.txt \\\n",
    "    --debug > profile/kaldi/dictionary.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedroom b 'E d r u m\r\n",
      "blue b l 'u\r\n",
      "closed k l 'o U z d\r\n",
      "cold k 'o U l d\r\n",
      "door d 'O r\r\n",
      "garage g 3 'A Z\r\n",
      "green g r 'i n\r\n",
      "hot h 'A t\r\n",
      "how h 'aU\r\n",
      "is 'I z\r\n"
     ]
    }
   ],
   "source": [
    "# Custom dictionary\n",
    "! head profile/kaldi/dictionary.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guess unknown word pronunciations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting profile/unknown_words.txt\n"
     ]
    }
   ],
   "source": [
    "%%file profile/unknown_words.txt\n",
    "test\n",
    "ploop\n",
    "raxacoricofallipatorius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\r\n",
      "  \u001b[0m\u001b[34;1m\"test\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\r\n",
      "    \u001b[0;32m\"t 'E s t\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"t E s t\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"t V s t\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"t I s t\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"t 'i s t\"\u001b[0m\u001b[1;39m\r\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"ploop\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\r\n",
      "    \u001b[0;32m\"p l 'u p\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"p l u p\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"p l o U 'O p\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"p l 'u p 'i\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"p l 'A A p\"\u001b[0m\u001b[1;39m\r\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"raxacoricofallipatorius\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\r\n",
      "    \u001b[0;32m\"r '{ k s V k 'A r I k O f '{ l V p V t O r i I s\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"r '{ k s V k 'A r I k O f '{ l V p V t 'O r i I s\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"r '{ k s V k O r 'i k o U f '{ l V p V t O r i I s\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"r '{ k s V k O r 'i k o U f '{ l V p V t 'O r i I s\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"r '{ k s V k 'O r I k O f '{ l V p V t O r i I s\"\u001b[0m\u001b[1;39m\r\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m\r\n",
      "\u001b[1;39m}\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Guesses can be added to dictionary as:\n",
    "# <WORD> <PHONEMES>\n",
    "! rhasspy-vocab_g2p \\\n",
    "    --model profile/kaldi/g2p.fst \\\n",
    "    < profile/unknown_words.txt | \\\n",
    "  jq ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate HCLG.fst\n",
    "\n",
    "Kaldi models require an additional training step to generate a special finite state transducer (FST) named `HCLG.fst`. This FST merges acoustic, pronunciation, and language model information, allowing Kaldi to do fast transcriptions.\n",
    "\n",
    "Assumes `profile/kaldi` contains:\n",
    "\n",
    "* `model` (nnet3)\n",
    "* `dictionary.txt` (from training)\n",
    "* `language_model.txt` (from training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fstisstochastic /home/hansenm/opt/rhasspy-services/docs/notebooks/profile/kaldi/model/graph/HCLGa.fst \r\n",
      "-0.660182 -2.19459\r\n",
      "HCLGa is not stochastic\r\n",
      "add-self-loops --self-loop-scale=0.1 --reorder=true /home/hansenm/opt/rhasspy-services/docs/notebooks/profile/kaldi/model/model/final.mdl /home/hansenm/opt/rhasspy-services/docs/notebooks/profile/kaldi/model/graph/HCLGa.fst \r\n",
      "Preparing online decoding\r\n",
      "/home/hansenm/opt/rhasspy-services/build/kaldi-master/egs/wsj/s5/steps/online/nnet3/prepare_online_decoding.sh --mfcc-config /home/hansenm/opt/rhasspy-services/docs/notebooks/profile/kaldi/model/conf/mfcc_hires.conf /home/hansenm/opt/rhasspy-services/docs/notebooks/profile/kaldi/model/data/lang /home/hansenm/opt/rhasspy-services/docs/notebooks/profile/kaldi/model/extractor /home/hansenm/opt/rhasspy-services/docs/notebooks/profile/kaldi/model/model /home/hansenm/opt/rhasspy-services/docs/notebooks/profile/kaldi/model/online\r\n",
      "/home/hansenm/opt/rhasspy-services/build/kaldi-master/egs/wsj/s5/steps/online/nnet3/prepare_online_decoding.sh: preparing configuration files in /home/hansenm/opt/rhasspy-services/docs/notebooks/profile/kaldi/model/online/conf\r\n",
      "/home/hansenm/opt/rhasspy-services/build/kaldi-master/egs/wsj/s5/steps/online/nnet3/prepare_online_decoding.sh: moving /home/hansenm/opt/rhasspy-services/docs/notebooks/profile/kaldi/model/online/conf/online.conf to /home/hansenm/opt/rhasspy-services/docs/notebooks/profile/kaldi/model/online/conf/online.conf.bak\r\n",
      "/home/hansenm/opt/rhasspy-services/build/kaldi-master/egs/wsj/s5/steps/online/nnet3/prepare_online_decoding.sh: created config file /home/hansenm/opt/rhasspy-services/docs/notebooks/profile/kaldi/model/online/conf/online.conf\r\n",
      "Training succeeded\r\n"
     ]
    }
   ],
   "source": [
    "# Generate HCLG.fst in profile/kaldi/model/graph\n",
    "! rhasspy-kaldi-train \\\n",
    "    --model-dir profile/kaldi/model \\\n",
    "    --model-type nnet3 \\\n",
    "    --dictionary profile/kaldi/dictionary.txt \\\n",
    "    --language-model profile/language_model.txt \\\n",
    "  2>&1 | \\\n",
    "  tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to Text (Kaldi)\n",
    "\n",
    "Transcribing an audio segment with [Kaldi](https://kaldi-asr.org) a trained model with the following artifacts:\n",
    "\n",
    "1. An acoustic model (`final.mdl`)\n",
    "2. An acoustic-phonetic-lingustic FST (`HCLG.fst`)\n",
    "3. A symbol table (`words.txt`)\n",
    "\n",
    "Assumes `profile/kaldi` contains:\n",
    "\n",
    "* `model` (nnet3)\n",
    "    * `graph`\n",
    "        * `HCLG.fst`\n",
    "        * `words.txt`\n",
    "    * `model`\n",
    "        * `final.mdl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\r\n",
      "  \u001b[0m\u001b[34;1m\"text\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"turn on the living room lamp\"\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"wav_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"tmpzg069bi0.wav\"\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"wav_seconds\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m2.412562\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"transcribe_seconds\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0.581928\u001b[0m\u001b[1;39m\r\n",
      "\u001b[1;39m}\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Requires 16-bit 16Khz mono audio\n",
    "! gst-launch-1.0 \\\n",
    "    filesrc location=wav/turn_on_living_room_lamp.wav ! \\\n",
    "    decodebin ! \\\n",
    "    audioconvert ! \\\n",
    "    audioresample ! \\\n",
    "    audio/x-raw, rate=16000, channels=1, format=S16LE ! \\\n",
    "    filesink location=/dev/stdout | \\\n",
    "  rhasspy-kaldi \\\n",
    "    --model-dir profile/kaldi/model \\\n",
    "    --model-type nnet3 | \\\n",
    "  jq ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decode multiple WAV files (jsonl output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wav_files.txt\n"
     ]
    }
   ],
   "source": [
    "%%file wav_files.txt\n",
    "wav/turn_on_living_room_lamp.wav\n",
    "wav/what_time_is_it.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\r\n",
      "  \u001b[0m\u001b[34;1m\"text\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"turn on the living room lamp\"\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"wav_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"turn_on_living_room_lamp.wav\"\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"wav_seconds\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m2.402375\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"transcribe_seconds\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0.47668\u001b[0m\u001b[1;39m\r\n",
      "\u001b[1;39m}\u001b[0m\r\n",
      "\u001b[1;39m{\r\n",
      "  \u001b[0m\u001b[34;1m\"text\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"what time is it\"\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"wav_name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"what_time_is_it.wav\"\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"wav_seconds\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m2.218667\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"transcribe_seconds\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0.440229\u001b[0m\u001b[1;39m\r\n",
      "\u001b[1;39m}\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Reads list of WAV files to decode from stdin\n",
    "! rhasspy-kaldi-decode \\\n",
    "    --model-dir profile/kaldi/model \\\n",
    "    --model-type nnet3 \\\n",
    "    < wav_files.txt | \\\n",
    "  jq ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent Recognition (fsticuffs)\n",
    "\n",
    "Assumes `profile` contains:\n",
    "\n",
    "* `intent.fst` (from training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\r\n",
      "  \u001b[0m\u001b[34;1m\"text\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"turn on the living room lamp\"\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"intent\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\r\n",
      "    \u001b[0m\u001b[34;1m\"name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"ChangeLightState\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0m\u001b[34;1m\"confidence\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\r\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"entities\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\r\n",
      "    \u001b[1;39m{\r\n",
      "      \u001b[0m\u001b[34;1m\"entity\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"state\"\u001b[0m\u001b[1;39m,\r\n",
      "      \u001b[0m\u001b[34;1m\"value\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"on\"\u001b[0m\u001b[1;39m,\r\n",
      "      \u001b[0m\u001b[34;1m\"raw_value\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"on\"\u001b[0m\u001b[1;39m,\r\n",
      "      \u001b[0m\u001b[34;1m\"start\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m5\u001b[0m\u001b[1;39m,\r\n",
      "      \u001b[0m\u001b[34;1m\"end\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m7\u001b[0m\u001b[1;39m\r\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[1;39m{\r\n",
      "      \u001b[0m\u001b[34;1m\"entity\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"name\"\u001b[0m\u001b[1;39m,\r\n",
      "      \u001b[0m\u001b[34;1m\"value\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"living room lamp\"\u001b[0m\u001b[1;39m,\r\n",
      "      \u001b[0m\u001b[34;1m\"raw_value\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"living room lamp\"\u001b[0m\u001b[1;39m,\r\n",
      "      \u001b[0m\u001b[34;1m\"start\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m12\u001b[0m\u001b[1;39m,\r\n",
      "      \u001b[0m\u001b[34;1m\"end\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m28\u001b[0m\u001b[1;39m\r\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\r\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"raw_text\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"turn on the living room lamp\"\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"tokens\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\r\n",
      "    \u001b[0;32m\"turn\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"on\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"the\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"living\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"room\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"lamp\"\u001b[0m\u001b[1;39m\r\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"raw_tokens\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\r\n",
      "    \u001b[0;32m\"turn\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"on\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"the\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"living\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"room\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"lamp\"\u001b[0m\u001b[1;39m\r\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"slots\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\r\n",
      "    \u001b[0m\u001b[34;1m\"state\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"on\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0m\u001b[34;1m\"name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"living room lamp\"\u001b[0m\u001b[1;39m\r\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"intents\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[]\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"recognize_seconds\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0.0023703575134277344\u001b[0m\u001b[1;39m\r\n",
      "\u001b[1;39m}\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Sentences are read line-by-line from stdin\n",
    "# when --text-input is given.\n",
    "! echo 'turn on the living room lamp' | \\\n",
    "  rhasspy-fsticuffs \\\n",
    "    --intent-fst profile/intent.fst \\\n",
    "    --text-input | \\\n",
    "  cut -d' ' -f2- | \\\n",
    "  jq ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\r\n",
      "  \u001b[0m\u001b[34;1m\"text\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"turn on living room lamp\"\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"intent\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\r\n",
      "    \u001b[0m\u001b[34;1m\"name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"ChangeLightState\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0m\u001b[34;1m\"confidence\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m\r\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"entities\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\r\n",
      "    \u001b[1;39m{\r\n",
      "      \u001b[0m\u001b[34;1m\"entity\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"state\"\u001b[0m\u001b[1;39m,\r\n",
      "      \u001b[0m\u001b[34;1m\"value\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"on\"\u001b[0m\u001b[1;39m,\r\n",
      "      \u001b[0m\u001b[34;1m\"raw_value\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"on\"\u001b[0m\u001b[1;39m,\r\n",
      "      \u001b[0m\u001b[34;1m\"start\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m5\u001b[0m\u001b[1;39m,\r\n",
      "      \u001b[0m\u001b[34;1m\"end\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m7\u001b[0m\u001b[1;39m\r\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[1;39m{\r\n",
      "      \u001b[0m\u001b[34;1m\"entity\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"name\"\u001b[0m\u001b[1;39m,\r\n",
      "      \u001b[0m\u001b[34;1m\"value\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"living room lamp\"\u001b[0m\u001b[1;39m,\r\n",
      "      \u001b[0m\u001b[34;1m\"raw_value\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"living room lamp\"\u001b[0m\u001b[1;39m,\r\n",
      "      \u001b[0m\u001b[34;1m\"start\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m8\u001b[0m\u001b[1;39m,\r\n",
      "      \u001b[0m\u001b[34;1m\"end\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m24\u001b[0m\u001b[1;39m\r\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\r\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"raw_text\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"turn on living room lamp\"\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"tokens\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\r\n",
      "    \u001b[0;32m\"turn\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"on\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"living\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"room\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"lamp\"\u001b[0m\u001b[1;39m\r\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"raw_tokens\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\r\n",
      "    \u001b[0;32m\"turn\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"on\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"living\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"room\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0;32m\"lamp\"\u001b[0m\u001b[1;39m\r\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"slots\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\r\n",
      "    \u001b[0m\u001b[34;1m\"state\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"on\"\u001b[0m\u001b[1;39m,\r\n",
      "    \u001b[0m\u001b[34;1m\"name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"living room lamp\"\u001b[0m\u001b[1;39m\r\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"intents\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[]\u001b[0m\u001b[1;39m,\r\n",
      "  \u001b[0m\u001b[34;1m\"recognize_seconds\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0.0007712841033935547\u001b[0m\u001b[1;39m\r\n",
      "\u001b[1;39m}\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Do fuzzy matching (usually slower).\n",
    "# Skip over any unknown words.\n",
    "! echo \"would you please turn on that good ol' living room lamp of mine\" | \\\n",
    "  rhasspy-fsticuffs \\\n",
    "    --intent-fst profile/intent.fst \\\n",
    "    --skip-unknown \\\n",
    "    --fuzzy \\\n",
    "    --text-input | \\\n",
    "  cut -d' ' -f2- | \\\n",
    "  jq ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
